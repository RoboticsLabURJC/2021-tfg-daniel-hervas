{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Practice 1</h1>\n",
    "<h2 align=\"center\">Introduction to digital image processing</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Reading, writing and viewing images\n",
    "\n",
    "In this Notebook we are going to be using 3 python lybraries commonly used for image processing:\n",
    "\n",
    "    -OpenCV: Open Source Computer Vision Library\n",
    "    -Numpy: The fundamental package for scientific computing with Python\n",
    "    -Matplotlib: a Python 2D plotting library\n",
    "The first thing we are going to do is import these libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to read an image (*'lena.jpg'*) using the function `imread` from OpenCV. You can find information about it's arguments and output in this [link](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_image_display/py_image_display.html).\n",
    "\n",
    "It's important to make sure that the image we are trying to read is in the current directory, as in this case. If not, just specify an absolute path indicating the location of the file. Keep in mind that if the image is not found python won't raise an exception, but `imread` will return a null array.\n",
    "\n",
    "(Try using print to see your matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about the image we just read we can use the attributes *size*, *shape*, *dtype*. \n",
    "[More information about numpy types](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.types.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the image we have a function in two of the imported libraries: *opencv* and *matplotlib*.\n",
    "The *opencv* option opens the image in a separate window and requires the function `waitKey` to work. To close the windows you can use the function `destroyAllWindows`. [link to more information](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_image_display/py_image_display.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other option to view images is also the `imshow` method, this time within *matplotlib* library. This option allows the image to appear directly on the Notebook. To see the different parameters go to the next [link](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.imshow.html), after `imshow` to actually see the image use the function `show` from *matplotlib*.\n",
    "\n",
    "Try to view the color image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few useful commands to hide ticks and borders. For this code to work make sure to put your own variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgcolor)\n",
    "plt.xticks([]), plt.yticks([])  # this hides the axis ticks\n",
    "for spine in plt.gca().spines.values():  #hide image border\n",
    "    spine.set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Matplotlib* also allows the option of zooming the image and a cursor that gives the value of the pixel it's hovering over. When using this option it's important to remember to use `plt.figure()`, when not used it will paint over the last figure.\n",
    "[About matplotlib notebook](https://medium.com/@1522933668924/using-matplotlib-in-jupyter-notebooks-comparing-methods-and-some-tips-python-c38e85b40ba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.figure(1)\n",
    "plt.imshow(imgcolor)\n",
    "plt.xticks([]), plt.yticks([])  # this hides the axis ticks\n",
    "for spine in plt.gca().spines.values():  #hide image border\n",
    "    spine.set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the color image is not correct, this is because of the color space used on *OpenCV*. *OpenCV* reads color images as BGR (Blue Green Red), whereas *matplotlib* displays RGB (Red Green Blue). To see the image correctly is necessary to change color spaces.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to change color spaces\n",
    "\n",
    "*OpenCV* has a function that allows you to change the color space of an image, it's `cvtcolor`. This function has a lot of possible transformations as you can see when you run the next cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flags = flags = [i for i in dir(cv2) if i.startswith('COLOR_')]\n",
    "\n",
    "print(flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the color image we have loaded as an example. We want to change it from BGR to RGB so *matplotlib* can show the image correcty (*cv2.COLOR_BGR2RGB*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform a grey scale image to binary**\n",
    "\n",
    "To go from a color image to a gray image we can just read de image as a one dimension image with `imread`, or use `cvtcolor` with the argument *COLOR_RGB2GRAY*.\n",
    "\n",
    "To go from gray to binary we will use de function `Threshold`, the documentation for this function is in the next [link](https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html?highlight=threshold#cv2.threshold).\n",
    "\n",
    "When choosing the intensity level for the threshold it's important to know what you are going to use this binary image for. This threshold can be chosen manually but, there are also algorithms designed to find the best possible threshold, for example Otsu, these algorithms are also possible arguments for the `Threshold` function.\n",
    "\n",
    "It is also important to choose the *maxvalue* property best suited for your image. Normally binary images use the values 0 and 1, so the max value should be 1. To display gray scale images use *cmap = 'gray'* as the second argument for `plt.imshow`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From binary to color image**\n",
    "\n",
    "To go from a binary image to an RGB image first we need to create a color map. A color map is a matrix that assigns RGB values the different intensity leves in our original image. For example a color map for a binary image is 2X3 matrix, since we have 2 original intensity values, if we had a gray scale 8-bit image we would need a 256X3 color map.\n",
    "\n",
    "To create a color map it's necessary to import the *colors* package from *matplotlib*, we will be using the function [ListedColorMap](https://matplotlib.org/api/_as_gen/matplotlib.colors.ListedColormap.html#matplotlib.colors.ListedColormap) to create a new color map and apply it to our image.\n",
    "\n",
    "Build manually a color map that makes the white pixels of our image red and the black ones yellow.\n",
    "\n",
    "More information about color maps:[1](https://matplotlib.org/api/_as_gen/matplotlib.colors.Colormap.html#matplotlib.colors.Colormap) [2](https://matplotlib.org/tutorials/colors/colormap-manipulation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as mpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From RGB to indexed image with 255 levels.**\n",
    "\n",
    "These colormap allows us to create a new type of image that <font color=green> weighs less, occupies less in memory </font>. These images are indexed images, that consist of a matrix with the same rows and columns as the original image and another matrix that is the colormap. This means that if you have an RGB image with 8-bit pixel depth it will weight *numberofpixel*x3x8 bits, but when that image is an indexed image it will be *npixelx*+(*levels*x3x8). The levels indicate the number of colors the indexed image has.\n",
    "\n",
    "Since *OpenCV* doesn't have a function to go from RGB to index we will be using the matrices already given in '*map255.mat*' file,the matrices will be saved in a dictionary called *maps* that contains the following matrices: \n",
    "    - lenaind256\n",
    "    - map256    \n",
    "    - lenaind5    \n",
    "    - map5    \n",
    "    - lenagray5    \n",
    "    - mapgray5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "maps = sio.loadmat('map255.mat')\n",
    "\n",
    "print(maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the matrices *map256* and *lenaind256* from the dictionary, display *lenaind256* as an image in gray scale.\n",
    "Use the function `ListedColormap` to save *map256* as a Colormap and display the indexed image *lenaind256* with the new colormap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From RGB to indexed image with 5 levels.**\n",
    "\n",
    "In this section do the same as in the last, but with the matrices *lenaind5* and *map5*. This are generated as an indexed image with only 5 levels, which means there are only 5 colors in the final image. Can you apreciate the difference in the image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From gray scale to indexed image with 5 levels.**\n",
    "\n",
    "Repeat with *lenagray5* and *mapgray5*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save an image to a specified file use the function [imwrite](https://docs.opencv.org/3.0-alpha/modules/imgcodecs/doc/reading_and_writing_images.html#imwrite)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Changing the spatial and intensity resolution of an image\n",
    "\n",
    "Spatial resolution of an image refers to the number of pixels per row and column. To modify it *OpenCV* has the function [resize](https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html#void%20resize(InputArray%20src,%20OutputArray%20dst,%20Size%20dsize,%20double%20fx,%20double%20fy,%20int%20interpolation).\n",
    "\n",
    "Take the gray image of Lena with it's orginal size being 512X512:\n",
    "- Resize it to a 256X256 image\n",
    "- Resize it to a 128X128 image\n",
    "\n",
    "Show the 3 images side by side to apreciate the difference. Using cv2.imshow() it will be easier to see the difference since the windows will be of a different size each. Another way to see the images side by side is with [plt.subplot](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplot.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For use of cv2.imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the smaller image from the last question and resize it to it's original spatial resolution using different interpolations (nearest and bilinear). The interpolation is the method used by the resize function to stimate the values of the new pixels created by enlarging an image.\n",
    "Show the 3 images (original lena, and the 2 new just generated) side by side to apreciate the difference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For use of cv2.imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intensity resolution refers to the number of bits used for each pixel wich marks the number of intensity levels in an image. A normal gray scale image has 8 bits per pixel. An RGB image has 8 bits per pixel multiplied by 3 for each color.\n",
    "\n",
    "To change the intensity resolution of our image we will be using basic math applied directly to our image matrix, dividing the maximum level of our image 255 in this case) by the number given by this formula: X*n = 256 (being n the number of levels we want).\n",
    "\n",
    "- Change the levels of intensity in Lena to 16, 4 and 2 and save them in this variables Lena_512_16, Lena_512_4 y Lena_512_2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 2 levels we can use threshold\n",
    "Lena_512_2 = imgotsu\n",
    "\n",
    "#4 levels left as example repeat for 16 levels.\n",
    "temp = imggray/64\n",
    "temp = np.around(temp)\n",
    "Lena_512_4 = temp*64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Histogram and contrast enhacement\n",
    "\n",
    "A histogram is a way of <font color=green>representing</font> the pixels of an image that plots the intensity in the x axis and the number of pixels in the y axis, this allows you to easily see the tonal distribution of an image.\n",
    "\n",
    "*Matplotlib* has an specific function for this representation: [hist](https://docs.opencv.org/3.1.0/d1/db7/tutorial_py_histogram_begins.html).\n",
    "\n",
    "Display the histograms of the following images: \n",
    "    - Original gray Lena\n",
    "    - Lena_512_16\n",
    "    - Lena_512_4\n",
    "    - Lena_512_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tonal distribution of an image is linked to it's contrast, in general we can say that an image has a better contrast when it's histogram is wider, or it's intensity is not concentrated around one specific value. \n",
    "\n",
    "One way to improve the contrast of an image is through [histogram equalization](https://homepages.inf.ed.ac.uk/rbf/HIPR2/histeq.htm).\n",
    "\n",
    "*OpenCV* has a function for this: [equalizehist](https://docs.opencv.org/2.4/modules/imgproc/doc/histograms.html?highlight=equalizehist).\n",
    "\n",
    "Read the image '*lanscape.jpg*' and equalize its histogram. Display both the original and new histograms and both images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV.Interpretation of colour\n",
    "\n",
    "Load the image '*peppers.jpeg*', look up its shape and display it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the histogram of each one of the colour components (R, G, B). Remember to change this code to suit your variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = ('b','g','r')\n",
    "plt.figure('hist')\n",
    "for i,col in enumerate(color):\n",
    "    histr = cv2.calcHist([peppers],[i],None,[256],[0,256])\n",
    "    plt.plot(histr,color = col)\n",
    "    plt.xlim([0,256])\n",
    "\n",
    "plt.xlabel('Intensity')\n",
    "plt.ylabel('Number of pixels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the different channels of the image using the function [split](https://docs.opencv.org/2.4/modules/core/doc/operations_on_arrays.html?#split).\n",
    "\n",
    "Display the red channel of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get the negative of the red channel. To make the negative substract 255 (max value in an image with pixel depth 8) to the image. Keep in mind the order of the operation since an image can´t have negative values. Display this negative.\n",
    "\n",
    "Remerge the image with your new red channel and the original blue and green channels (use the function `cv2.merge`) an display this new image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two matrices of zeros with the same number of rows and columns as the image peppers and merge them with the original red channel to create a representation of only the red channel of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
