{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Follow Face Practice\n",
    "---\n",
    "<img src=\"resources/jderobot.svg\" width=\"15%\" height=\"15%\" style=\"float:left;padding-right:15px\"/>\n",
    "\n",
    "## 1 - Introduction\n",
    "---\n",
    "In this practice, the intention is to use your knowledge in image processing to \n",
    "segment people's face and follow it through a camera connected by USB to \n",
    "your computer. For this, you must have the right hardware (Sony model EVI d100p),\n",
    "and then implement the logic that performs the segmentation of a face and the\n",
    "data collection, as well as its transformation into orders for the camera's \n",
    "actuators, which must follow the movement of the person.\n",
    "\n",
    "To do it, the student needs to have at least the next knowledge:\n",
    "* Color spaces (RGB, HSV, etc)\n",
    "* Python programming skills\n",
    "* Basic understanding of [OpenCV library](http://opencv.org/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2 - Exercise components\n",
    "---\n",
    "<img src=\"resources/sonyevi.png\" width=\"20%\" height=\"15%\" style=\"float:right;padding-right:20px\"/>\n",
    "### 2.1 ROS usb-cam Driver\n",
    "This driver will be running in the background, and is responsible for extracting the image from the captor.\n",
    "### 2.1 Evi Cam Driver\n",
    "This one employs an ICE interface to teleoperate a real Sony camera model Evi d100p (the one shown in the image on the right).\n",
    "\n",
    "### 2.3 Printer\n",
    "This class prints an image in a Jupyter Notebook for debugging purposes. It will receive processed images from Follow Face to debug our algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Exercise initialization\n",
    "---\n",
    "To start coding, we need to call ``Follow Face`` class once. Run this code and wait a few seconds until follow face initialization finishes with an ``OK`` message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from follow_face import FollowFace\n",
    "from printer import printImage\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "ff = FollowFace()\n",
    "ff.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start coding to give intelligence to the camera. We can do it modifying the ``execute()`` method from Follow Face component. This method will be called iteratively about 10 times per second. To understand how it works, we are going to print a message in each iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement execute method\n",
    "def execute(self):\n",
    "    print \"Running execute iteration\"\n",
    "      \n",
    "ff.setExecute(execute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop printing updating the method with an empty code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(self):\n",
    "    pass\n",
    "      \n",
    "ff.setExecute(execute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - API:\n",
    "---\n",
    " - You can see the last saved image running this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imageCamera = ff.get_color_image()\n",
    "printImage(imageCamera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### USE:\n",
    " - to save the last segmented image:\n",
    " ```\n",
    " self.set_threshold_image(img)\n",
    " ```\n",
    " - to save the last camera's image:\n",
    " ```\n",
    " self.set_color_image(img)\n",
    " ```\n",
    " - to move camera:\n",
    "  ```\n",
    " self.move_camera(pan, tilt)\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Programming a face segmentation\n",
    "---\n",
    "To accomplish this exercise the student has to implement the logic for a <font color=green>face detection</font>, that is, to segmnet any faces on the image and detects its position inside it.\n",
    "\n",
    "Thus, given an input image like this image:\n",
    "\n",
    "![Input image](resources/input.png \"Input image\")\n",
    "\n",
    "The expected output would be similar to this image:\n",
    "\n",
    "![Output image](resources/output.png \"Output image\")\n",
    "\n",
    "To obtain this result, the proposed pipeline is:\n",
    "\n",
    "1. Collect Cascade Classifiers\n",
    "2. Face Detection\n",
    "3. Rectangle approximation\n",
    "4. Calculate new Pan and Tilt values\n",
    "5. Send orders to the camera to follow the segmented\n",
    "\n",
    "The first three steps can be easily conducted using [OpenCV library](https://opencv.org/ \"OpenCV\")\n",
    "Once done it, you will hace to manage the segmentation data to obtain the position of the face and transform those into accepted values for the camera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 - Collect Cascade Classifiers\n",
    "Object Detection using Haar feature-based cascade classifiers is an effective object detection method, since it uses a machine learning based approach where a cascade function is trained from a lot of positive and negative images.\n",
    "You may need different cascade clasiffiers for each characteristic you want to recognize (face, eyes, glasses,...). It is up to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Face Detection\n",
    "For these kind of problems, it is easier to find faces in a gray scale image than trying to find them in a colored one (greater changing background). Therefore, from now on, we will use a gray image, for which [OpenCV library](https://opencv.org/ \"OpenCV\") provides easy-to-use functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - Rectangle approximation\n",
    "Once obtained face's coordinates in the input image, those points can be approximated to polygons using the OpenCV [rectangle](https://docs.opencv.org/2.4/modules/core/doc/drawing_functions.html?highlight=rectangle#rectangle) function, which will draw the final rectangle in the image.\n",
    "\n",
    "It may be possible to obtain a set of coordinates defining different faces found, so we recommend to filter the calculated rectangles to show only the one belonging to the (main) face. You can pick up the proper rectangle setting up some restrictions, like rectangle size or shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Calculate new Pan and Tilt values\n",
    "If you have reached these step, you will already have the previously mentioned output image:\n",
    "![Output image](resources/output.png \"Output image\")\n",
    "So now, you hace to process the collected data and make it look like \"understandable orders for the camera\". For that, you will have to make a conversion between the pixels that define the position of the face, and the degrees by which the movement of the camera is defined.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Send orders to the camera to follow the segmented\n",
    "Finally, use those calculated values of the previous step to send orders to the camera, so that it can follow your face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Algorithm skeleton\n",
    "---\n",
    "We provide an skeleton where you can code your face filtering following the previous steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(self):\n",
    "      \n",
    "    # Get image\n",
    "    input_image = self.getImage()\n",
    "    if input_image is not None:\n",
    "        # Save camera's image\n",
    "        self.set_color_image(input_image)\n",
    "\n",
    "        # Collect Cascade Classifiers\n",
    "        # Add your code here\n",
    "\n",
    "        # Face Detection\n",
    "        # Add your code here\n",
    "        # find the center of the face (since it is the point you will follow)\n",
    "        \n",
    "        # Rectangle approximation\n",
    "        # Add your code here\n",
    "        \n",
    "        # Save segmented image\n",
    "        self.set_threshold_image(output_img) #output\n",
    "\n",
    "        # Calculate new Pan and Tilt values\n",
    "        # Add your code here\n",
    "        \n",
    "        # Send orders to the camera to follow the segmented\n",
    "        # Add your code here\n",
    "        \n",
    "\n",
    "ff.setExecute(execute)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
