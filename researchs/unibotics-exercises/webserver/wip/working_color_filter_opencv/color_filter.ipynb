{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual perception from your local camera\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Introduction\n",
    "\n",
    "<img src=\"images/filteredImage.png\" width=\"35%\" height=\"35%\" style=\"float:right;padding:1px\"/>\n",
    "In this exercise we are going to implement a color filter to segment an object in an image provided either by your local camera, a local video file or an external camera controlled by a ROS/ICE plugin. By default, this notebook will get images from your local video device, such as webcams. To resolve this exercise, the student needs to have at least the next knowledge:\n",
    "\n",
    "- Color spaces (RGB, HSV, etc)\n",
    "- Python programming skills\n",
    "- Basic understanding of [OpenCV library](http://opencv.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Exercise components\n",
    "\n",
    "### 2.1 Local Camera\n",
    "\n",
    "The video device that your computer includes by default (this is: the one in /dev/video0) will be the main component of this exercise. Ir provides a Class which abstracts a Camera from a local device, and provides the methods to keep it constantly updated, so that we will be able to get images from it.\n",
    "\n",
    "This exercise also allows selecting the video source that we want to use. Although it is intended to solve the exercise of the filter through the student's local camera, he/she can also select another video source (video file stored in the local file system or a camera via ROS / ICE) through the configuration file 'color_filter_conf.yml'.\n",
    "\n",
    "\n",
    "![selectablesource](images/selectablesource.png \"Selectable Video Source\")\n",
    "\n",
    "### 2.2 Color Filter component\n",
    "\n",
    "This component has been developed specifically to carry out this exercise. This component connects to the video source to receive images from it.\n",
    "\n",
    "The student has to modify this component and add code to accomplish the exercise. In particular, it is required to modify the ``execute()`` method.\n",
    "\n",
    "### 2.3 Printer\n",
    "\n",
    "This class prints an image in a Jupyter Notebook for debugging purposes. It will receive processed images from Color Filter to debug our algorithm, or any other image you want to see. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Exercise initialization\n",
    "\n",
    "To start coding, we need to use ``ColorFilter`` class. You will need to modify its execute() method, and the run your code through its play() method. Once you have coded your solution to the exercise, go to the end of **block 3** and click \"Play Code\". You will see the message ``Color filter is running``, and then your code will be executed.\n",
    "\n",
    "To code the execute() method, follow these instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you want to use CameraServer (ROS/ICE), uncomment next lines.\n",
    "\n",
    "#import subprocess\n",
    "#cameraserver = subprocess.Popen((\"cameraserver\", \"cameraserver_conf.cfg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "#from IPython.display import HTML\n",
    "#import numpy as np\n",
    "#import cv2\n",
    "#from color_filter import ColorFilter\n",
    "#from printer import printImage, printVideo\n",
    "#%matplotlib inline\n",
    "\n",
    "# Init color filter\n",
    "# cf = ColorFilter()\n",
    "#cf.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once our video source is serving images, we can start coding to segment any object. With that putpose, we recommend you to use objects with plain colors, in such a way that the filter values are easier to adjust. We need to modify the ``execute()`` method from Color Filter component with the logic that implements the filter. This method will be called iteratively about 10 times per second. To understand how it works, we are going to print a message in each iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement execute method\n",
    "def execute(self):\n",
    "    print \"Running execute iteration\"\n",
    "      \n",
    "cf.setExecute(execute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop printing updating the method with an empty code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(self):\n",
    "    pass\n",
    "      \n",
    "cf.setExecute(execute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REMEMBER:** You can use the ``pause()`` method of ColorFilter class to do an \"*Academic Pause*\", so that you are able to pause your algorithm, make some changes in the ``execute()`` method and setting those changes as shown above, and then resume your algorithm execution by running the ``play()`` method:\n",
    "\n",
    "1.- Pause\n",
    "```\n",
    "cf.pause()\n",
    "```\n",
    "\n",
    "2.- Change execute() method\n",
    "```\n",
    "def execute(self):\n",
    "    #make some changes\n",
    "      \n",
    "cf.setExecute(execute)\n",
    "```\n",
    "3.- Resume\n",
    "```\n",
    "cf.play()\n",
    "```\n",
    "\n",
    "Or just use the follwing \"Play Code/Pause Code\" toggle button:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": true,
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chosen source: local camera (index 0)\n",
      "Color filter initialized OK\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b91bbbe71828483284e28c339452dd4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(ToggleButton(value=False, button_style=u'success', description=u'Play Code', icon=u'check', layout=Layout(margin=u'1% 0 0 30%')), ToggleButton(value=False, description=u'Enable Visualization', layout=Layout(margin=u'1% 0 0 1%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color filter is running\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/env python\n",
    "\n",
    "from color_filter import ColorFilter\n",
    "from printer import printImage, printVideo\n",
    "import ipywidgets as w\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "\n",
    "# Init color filter\n",
    "cf = ColorFilter()\n",
    "\n",
    "def playcode():\n",
    "    cf.play()\n",
    "    \n",
    "def pausecode():\n",
    "    cf.pause()\n",
    "    \n",
    "playpausebutton = w.ToggleButton(description='Play Code', button_style='success', icon='check', layout=w.Layout(margin='1% 0 0 30%'))\n",
    "\n",
    "def onclick(change):\n",
    "    if change['new']:\n",
    "        playpausebutton.description = \"Pause Code\"\n",
    "        playpausebutton.button_style ='danger'\n",
    "        playpausebutton.icon='stop'\n",
    "        playcode()\n",
    "    else: \n",
    "        playpausebutton.description = \"Play Code\"\n",
    "        playpausebutton.button_style ='success'\n",
    "        playpausebutton.icon='check'\n",
    "        pausecode()\n",
    "\n",
    "playpausebutton.observe(onclick, 'value')\n",
    "\n",
    "toggle = w.ToggleButton(description='Enable Visualization', layout=w.Layout(margin='1% 0 0 1%'))\n",
    "\n",
    "def on_click(change):\n",
    "    if change['new']:\n",
    "        toggle.description = \"Disable Visualization\"\n",
    "        cf.algorithm.visualizationEnabled = True\n",
    "    else: \n",
    "        toggle.description = \"Enable Visualization\"\n",
    "        cf.algorithm.visualizationEnabled = False\n",
    "        clear_output()\n",
    "        displaybuttons()\n",
    "\n",
    "toggle.observe(on_click, 'value')\n",
    "\n",
    "def displaybuttons(): \n",
    "    display(w.HBox((playpausebutton, toggle)))\n",
    "displaybuttons()\n",
    "cf.algorithm.displaybuttons = displaybuttons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Image manipulation\n",
    "\n",
    "Color filter receives images from your local camera in principle. To obtain these images you can run this code inside the``execute()`` method:\n",
    "\n",
    "```\n",
    "image_input = self.camera.getImage()\n",
    "```\n",
    "\n",
    "To debug our code and show the output, there are two images that can be visualized:\n",
    "\n",
    "- We can visualize an RGB image (three channels), employed to show the images received from the simulator or manipulate them. You can set this images with this code:\n",
    "\n",
    "```\n",
    "self.set_color_image(image_three_channels)\n",
    "```\n",
    "\n",
    "- We can visualize a gray image (one channels), employed to show the color filter result:\n",
    "\n",
    "```\n",
    "self.set_filtered_image(image_one_channels)\n",
    "```\n",
    "\n",
    "You can recover these images afterwards with these commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB image\n",
    "imageRGB = cf.get_color_image()\n",
    "\n",
    "# Filtered image\n",
    "filteredGray = cf.get_filtered_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To print any of these images in this Notebook, just recover it (get_color_image, get_filtered_image or getImage methd shown above), and then call the ``printImage()`` method, i.e:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: print the image provided from the camera\n",
    "imageCamera = cf.camera.getImage()\n",
    "printImage(imageCamera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Each 3 seconds, the ColorFilter Class will automatically try to print a filtered image (it will only print it if you have previously set a filtered image with the ``set_filtered_image(img)`` method as shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are also allowed to press the 'Show 10 frames' button below to print camera's images every two seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide_input": true,
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea36b60d2bce484b9329478b002c01c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>Button</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "Button(button_style=u'info', description=u'Show 10 frames', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf.show = False\n",
    "frames = 10\n",
    "def showCamera(ev):\n",
    "    for x in range(0, frames):\n",
    "        im = cf.camera.getImage()\n",
    "        cf.algorithm.set_color_image(im)\n",
    "        # Show color image\n",
    "        imageCamera = cf.get_color_image()\n",
    "        #filteredImage = cf.get_filtered_image()\n",
    "        printVideo(imageCamera)\n",
    "        #printVideo(filteredImage) \n",
    "        clear_output()\n",
    "    button = w.Button(button_style='info',description=\"Show \" + str(frames) + \" frames\")\n",
    "    button.on_click(showCamera)\n",
    "    display(button)\n",
    "    \n",
    "button = w.Button(button_style='info',description=\"Show \" + str(frames) + \" frames\")\n",
    "button.on_click(showCamera)\n",
    "display(button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Programming a color filter segmentation\n",
    "\n",
    "\n",
    "To accomplish this exercise the student has to implement a color filter that segments a box and detects its position inside the image.\n",
    "\n",
    "Thus, given an input image like this image:\n",
    "\n",
    "![Input image](images/inputImage.png \"Input image\")\n",
    "\n",
    "The expected output would be similar to this image:\n",
    "\n",
    "![Output image](images/filteredImage.png \"Output image\")\n",
    "\n",
    "To obtain this result, the proposed pipeline is:\n",
    "\n",
    "1. Smooth image\n",
    "2. RGB to HSV conversion\n",
    "3. Color filter\n",
    "4. Rectangle approximation\n",
    "5. Object detection\n",
    "\n",
    "This steps are detailed in the next sections and can be easily conducted using [OpenCV library](https://opencv.org/ \"OpenCV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 - Smooth image\n",
    "\n",
    "Image smoothing is useful to remove noise or imperfections in image. For this exercise, we recommend to use a *Gaussian Filter*, that can be found in OpenCV library as [GaussianBlur](https://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html?highlight=gaussianblur#gaussianblur). The expected result of this filter from the input image shown in previous section is this:\n",
    "\n",
    "![Smoothed image](images/smoothImage.png \"Smoothed image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 - RGB to HSV conversion\n",
    "\n",
    "The images received from your camera have an RGB color space. This color space is useful to represent digital images but it is also very sensitive to light changes. Therefore, the next step is to convert our RGB image into a HSV image. We recommend to use the [cvtColor](https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html#cvtcolor) function from OpenCV.\n",
    "\n",
    "If we print this image, the expected result will be similar to this image:\n",
    "\n",
    "![HSV image](images/hsvImage.png \"HSV image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 - Color filter\n",
    "\n",
    "Now we can apply our color filter to the HSV image. The OpenCV function [inRange](https://docs.opencv.org/2.4/modules/core/doc/operations_on_arrays.html?highlight=inrange#inrange) can help us to make this color filter.\n",
    "\n",
    "This function receives two arrays, the first one sets the lower HSV values of the filter, and the second one the upper values. For the first parameter (H), the expected values are in range [0, 180], whereas for S and V the values are in range [0, 255]. Thus, a filter where all pixels would be validated would have this appearance:\n",
    "\n",
    "```\n",
    "lower_values = np.array([0,0,0], dtype=np.uint8)\n",
    "upper_values = np.array([180,255,255], dtype=np.uint8)\n",
    "```\n",
    "\n",
    "Note: To represent arrays we employ the [numpy library](http://www.numpy.org/)\n",
    "\n",
    "Once the maximum and minimum values for each HSV parameters have been properly set, the thresholded image (with one channel) has to be similar to this one:\n",
    "\n",
    "![Thresholded image](images/thresholdImage.png \"Thresholded image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 - Rectangle approximation\n",
    "\n",
    "Trying to find a white object inside a black background is easier than trying to find a colored one inside a changing background. Therefore, from now on, we will use the thresholded image calculated in the previous step.\n",
    "\n",
    "One option to detect the box could be detecting the object contour with [findContours](https://docs.opencv.org/2.4/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html?highlight=findcontours#findcontours) function. This function modifies the input image, so we recommend to create a copy before using it with the [numpy copy](https://docs.scipy.org/doc/numpy/reference/generated/numpy.copy.html) function.\n",
    "\n",
    "FindContours returns a list of points that defines the object contour. This points can be approximated to polygons using one of the next OpenCV functions: [approxPolyDP](https://docs.opencv.org/2.4/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html?highlight=findcontours#approxpolydp) or [boundingRect](https://docs.opencv.org/2.4/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html?highlight=findcontours#boundingrect). You can also draw the obtained rectangle with [rectangle](https://docs.opencv.org/2.4/modules/core/doc/drawing_functions.html?highlight=rectangle#rectangle) function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 - Object detection\n",
    "\n",
    "Since color filtering parameters are not easy to adjust (even in simulated environments), there may be several image regions with rectangles calculated in previous step. One rectangle will belong to the box we are trying to detect, where as the rest will be noisy regions.\n",
    "\n",
    "In this case, we recommend to filter the calculated rectangles to show only the one belonging to the object you want to segment. You can pick up the proper rectangle setting up some restrictions, like rectangle size or shape deppending on the size of your selected object.\n",
    "\n",
    "The final result will be the output image we show at the beginning of this section.\n",
    "\n",
    "![Output image](images/filteredImage.png \"Output image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Algorithm skeleton\n",
    "\n",
    "We provide an skeleton where you can code your color filtering following the previous steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(self):\n",
    "      \n",
    "    # Get image\n",
    "    input_image = self.camera.getImage()\n",
    "    if input_image is None:\n",
    "        print \"Can't get images from camera, is your local camera working?\"\n",
    "        return\n",
    "    \n",
    "    if input_image.any(): \n",
    "        output_img = np.copy(input_image)\n",
    "        \n",
    "        # Smooth image\n",
    "        # Add your code here\n",
    "        \n",
    "        # RGB to HSV conversion\n",
    "        # Add your code here\n",
    "        \n",
    "        # Color filter\n",
    "        # Add your code here\n",
    "        \n",
    "        # Rectangle approximation\n",
    "        # Add your code here\n",
    "        \n",
    "        # Box detection\n",
    "        # Add your code here\n",
    "\n",
    "        # Save images\n",
    "        self.set_color_image(output_img)\n",
    "        #self.set_filtered_image(thresold_img)\n",
    "\n",
    "cf.setExecute(execute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see saved images running this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show color image\n",
    "imageCamera = cf.get_color_image()\n",
    "printImage(imageCamera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show filtered image\n",
    "imageCamera = cf.get_filtered_image()\n",
    "printImage(imageCamera)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
